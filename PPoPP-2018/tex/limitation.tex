\section{Limitation and Future Work}
SCache aims to mitigate shuffle overhead between DAG computing stages. And the evaluation results show a promising improvement. But we realize some limitations of SCache.

\textbf{Fault tolerance of SCache}: When a failure happens on the SCache master, the whole system will stop working. To prevent the inconsistency caused by failure, the master node logs the meta data of shuffle register and pre-scheduling results on the disk. Since we remove the shuffle transfer from the critical path of DAG computing, the disk logging will not introduce extra overhead to the DAG frameworks. Note that the master can be implemented with Apache ZooKeeper \cite{zookeeper} to provide constantly service. If a failure happens on a worker, the optimization of tasks on that node will fail. It also violates the all-or-nothing constraint. A promising way to solve the failure on a worker is to select some backup nodes to store replications of shuffle data during pre-scheduling to prevent the worker failure. In addition, there are also advanced fast recovery techniques such as FineFRC \cite{finefrc}. As for now, fault tolerance is not a crucial goal of SCache,  we leave it to the future work.

%\textbf{Scheduling with different frameworks}: A cluster for data parallel computing always contains more than one frameworks. Setting priority among jobs submitted from different framework is challenging. However, associating with the resource management facilities in data center such as Mesos \cite{mesos} may be a good direction. 

\textbf{Future optimization of Network}: Since the shuffle is decoupled, the network layer optimization, such as Varys \cite{varys} and Aalo \cite{aalo}, can be easily applied on SCache to further improve the performance of shuffle.