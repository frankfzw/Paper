%# -*- coding: utf-8-unix -*-
%%==================================================
%% conclusion.tex for SJTUThesis
%% Encoding: UTF-8
%%==================================================

\chapter{总结与展望}
\label{chap:summary}

本章对SCache的设计和实现进行总结。并对相应可能的发展方向进行展望。

\section{总结}

本文的主要贡献是实现了一个针对目前主流分布式DAG计算框架的shuffle优化方案。
本文首先通过了对现有的分布式DAG框架中的shuffle过程的特性进行观察和抽象，提取出共性的问题：
\begin{enumerate}
    \item 粗粒度的硬件资源管理
    \item 同步滞后的shuffle数据读取
    \item 低效率的磁盘操作
\end{enumerate}
基于这些共同问题，同时借助Spark作为观察对象来测试具体的shuffle在与计算任务相连接的工作特点，从而得出具有普遍意义的解决方案 --- SCache。
SCache首先通过内存拷贝的方式将shuffle的过程从map和reduce两端中分别解耦，使得shuffle过程独立与DAG计算框架进行管理。
同时，SCache通过获取DAG计算框架的任务执行数据等相关信息实现了对map阶段shuffle输出数据分布的预测，进而实现reduce阶段任务的预调度与shuffle数据预取。
通过预取的方式既打破了原来同步的shuffle读取给网络带来的瞬时巨大压力，有很好的隐藏了shuffle的显示网络传输时间。
最后，SCache通过结合应用上下文的shuffle数据内存缓存机制，在只占用有限内存的情况下，就能实现对reduce任务的shuffle数据的内存缓存，进一步加速了reduce阶段任务的执行。
在实现这些优化的同时，SCache通过对shuffle过程的抽象，提供了具有普适性的编程接口。
通过该编程接口，分布式DAG的计算框架只要改动少量源代码即可以实现对shuffle的优化。

本文在实现SCache的过程中使用了主从节点的分布式系统设计，并采用了RPC的方式实现了与DAG框架之间的通信。
通过RPC的方式实现同时也使得接口针对DAG框架本地化过程兼容性更好。
同时本文还详细展示了针对目前主流的Spark的适配过程。
为了更好的证明SCache优化的普适性，我们还展示了在Hadopp MapReduce中适配的相应流程和方向。

通过在Spark上适配SCache，并且在适配后的Spark上进行了一系列的测试。
在与原始的Spark进行比较之后，经过SCache优化后Spark在执行工作的过程中不仅提高了节点整体硬件资源的利用率和复用率，
同时在shuffle上的时间开销也显著缩短。
基于生产环境评测程序的测试更说明了在shuffle开销较大的工作中，即使在端到端的工作时间的维度上，SCache对shuffle的优化也能带来比较显著的效果。

综上所述，我们相信SCache对于目前主流的分布式DAG计算框架的shuffle都能提供较为简单高效的性能优化。

\section{展望}

SCache目前对于shuffle的优化还停留在单个计算框架中的一个工作，而对于多租户多工作下的shuffle数据块优化问题，这种方案则并不一定是最优的。
而在当前数据中心当中，一个分布式DAG计算框架同时运行多个任务的情况还是存在的。
特别是在Yarn\cite{yarn}和Mesos\cite{mesos}等机器资源管理平台的支持下，使得多工作同时运行在集群中的情况将会更加普遍。
为了实现在多工作同时运行时的shuffle优化，SCache可能需要将任务预调度机制下方到资源管理平台，以便获取全局的所有工作的shuffle依赖信息。

另外，在章节\ref{sec:relatedwork}中提到的网络层借用coflow的优化对于进一步降低shuffle的平均传输时间仍然具有积极的意义。
目前受限于EC2集群网络的不可控而无法进行有效的开发和测试。
而在章节\ref{sec:network}中展现的模拟实验结果也证明网络层的进一步优化是可行的。
在接下来的工作中也可以将这部分优化甚至更底层的网络优化，比如pFabric\cite{pfabric}等网络层的优化集成到SCache中，使得SCache在数据中心网络的特殊环境中能够获得更高的工作效率。


