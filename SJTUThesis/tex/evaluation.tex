%# -*- coding: utf-8-unix -*-
%%==================================================
%% chapter02.tex for SJTU Master Thesis
%%==================================================

\chapter{实验分析}
\label{chap:evaluation}

本章节将通过综合性的负载和评测软件来测试SCache对Spark性能的优化效果。
首先我们运行了一个只包含一个shuffle的简单DAG工作来分析硬件利用率的变化。
同时也从改工作中具体每个任务的角度来分析SCache的优化带来的影响。
之后我们使用了一个公认的含有大量shuffle数据的测试程序Terasort\cite{terasort}来测试不同分区函数下SCache带来的优化。

为了证明SCache能在真实生产环境中带来性能的提升，我们也通过Spark TPC-DS\footnote{https://github.com/databricks/spark-sql-perf}的测试程序来对SCache的优化效果进行测试。

最后我们测试了有权重的水塘采样过程给Spark计算带来的开销。

简短来讲，在SCache的帮助下，可以减少Spark计算过程中89\%的shuffle时间开销。
同时，在单shuffle的DAG程序中，SCache可以帮助Spark实现在reduce阶段75\%的性能提升。
对于Terasort的reduce阶段，在SCache的帮助下可以实现50\%的性能提升。
并且通过启发式预调度算法，相较于Spark调度所产生的经过网络的shuffle数据体积，SCache的优化在加快reduce阶段执行的同时并不会引入额外的网络负载。
在标准的分布式数据库查询评测程序TPC-DS的测试中，经过SCache对shuffle的优化，可以为其中的查询提供接近40\%的平均查询时间优化，效果十分显著。

\section{实验平台搭建}

我们在目前应用广泛的Spark分布式计算框架1.6.2版本中实现了SCache的守护进程，并且通过修改Spark任务调度器（DAGScheduler和TaskSchedulerImpl）来实现了对DAG中shuffle信息和相关任务信息的提交，SCache附属调度器调度结果的获取和采样程序的插入等。
同时，我们租用了亚马逊AWS EC2中50个m4.xlarge类型的节点作为测试平台，并且部署修改后的Spark和SCache。
每个节点的配置如下表所示：
\begin{table}[!hpb]
    \centering
    \bicaption[tab:ec2]{测试平台节点配置}{测试节点平台配置}{Table}{Configuration of Testbed Instance}
    \begin{tabular}{ | m{5cm} | m{8cm} | }
        \hline
        \multicolumn{2}{| c |}{Configuration of Testbed Instance}\\ [0.5ex]
        \hline
        \hline
        Instance Type & m4.xlarge \\ \hline
        CPU & 2.3 GHz Intel Xeon E5-2686 v4 (Broadwell) / 2.4 GHz Intel Xeon E5-2676 v3 (Haswell) \\ \hline
        vCPU & 4 \\ \hline
        Memory & 16GB \\ \hline
        Storage & 8GB SSD, bandwidth 750 Mbps \\ \hline
        Network Bandwidth & N/A, ($\sim$300Mbps as we tested) \\ \hline
        OS & Ubuntu 14.04 LTS \\ \hline
        \hline
    \end{tabular}
\end{table}

其中每个计算节点为一个EC2的虚拟实例，包含了4个vCPU以及16GB的内存和8GB的SSD存储。
以上这些硬件性能保证了在测试过程中计算和内存不会限制测试程序的计算运行速度，同时也为shuffle数据的缓存提供了较充足的内存空间。
为了为Spark计算提供存储资源，我们还在集群上部署了Hadoop 2.7\cite{hadoop}来提供HDFS的分布式文件系统支持。
除此之外，我们在集群上的每个节点部署了采集CPU磁盘网络等硬件资源利用情况的程序。

\section{单shuffle依赖的DAG执行分析}

我们首先展示了运行与图\ref{fig:util}中一样的，只包含一个shuffle依赖的Spark程序，即Spark GroupByTest\cite{sparksource}。
在此次评测中，我们分别采用了不同体积的输入数据，同时为每一个计算阶段分配了5轮的任务。

在图\ref{fig:scache_util}中展示了在SCache优化下执行该单shuffle依赖的程序时的硬件资源使用情况。
需要注意的时在SCache的优化下，使得整个工作的执行时间缩短了50\%，因此图\ref{fig:scache_util}中横坐标代表的时间长度只有图\ref{fig:util}的一半。
首先可以看到的就是在图\ref{fig:scache_util}中出现了CPU资源利用率峰值和磁盘，网络这些硬件资源利用率峰值的重合。
这个表明了通过SCache对shuffle的解耦以及预取，使得节点中硬件资源的利用率和复用率得到了很大的提升。
在更细粒度的硬件资源管理下，SCache避免了在原先Spark中因为I/O的操作而无效的占用计算资源的情况。
同时，由于CPU的资源能被更即使的释放和更少的空置，是的整个集群在计算过程中始终保持较高的CPU利用率。
以上这些硬件资源利用率上的增加和复用率的增加从资源管理效率的角度证明了在SCache的帮助下，Spark的任务能够被更高效的执行，从而获得更好的性能。

\begin{figure}[!htp]
	\centering
	\includegraphics[width=\textwidth]{../../PPoPP-2018/fig/scache_util.pdf}
	\bicaption[fig:scache_util]{SCache优化后运行包含一个shuffle的Spark应用时的硬件资源利用率}{SCache优化后运行包含一个shuffle的Spark应用时的硬件资源利用率}{Fig}{CPU utilization and I/O throughput of a node
	during a Spark Single Shuffle Application With SCache}
\end{figure}

于此同时，我们也在计算任务层面对两者进行了比较。
如图\ref{fig:groupbymapstage}所示，可以看到在map阶段，随着输入数据的体积增加，SCache通过解耦合的方式提前释放CPU资源，同时通过内存拷贝的方式省略磁盘操作能给map阶段的性能带来一个较为显著的提升。
SCache的优化在map阶段平均可以带来约10\%的性能提升。
而图\ref{fig:groupbyreducestage}展示了shuffle数据预取对于需要大量shuffle数据传输的应用，能在reduce阶段带来非常显著的性能提升。
这些提升正是因为SCache通过在map阶段对reduce任务实行预调度和shuffle数据的预取，提前了原先Spark模式中shuffle开始的时间，有效的将网络传输时间隐藏在map计算阶段，从而减少了reduce计算阶段启动之后显示的shuffle等待时间，加快了reduce阶段的任务执行。
对于reduce阶段，SCache带来的性能提升较为显著，平均可以达到大约75\%。
两者相结合，在对单shuffle依赖的工作的优化过程中，SCache可以减少大约89\%的平均shuffle时间开销。

\begin{figure}[!htp]
    \centering
    \begin{minipage}[t]{0.47\textwidth}
	    \includegraphics[width=\textwidth]{../../PPoPP-2018/fig/groupbymapstage.pdf}
	    \bicaption[fig:groupbymapstage]{单shuffle依赖工作的map阶段完成时间比较}{单shuffle依赖工作的map阶段完成时间比较}{Fig}{Map Stage Completion Time of Single Shuffle Test}
    \end{minipage}
    \begin{minipage}[t]{0.47\textwidth}
	    \includegraphics[width=\textwidth]{../../PPoPP-2018/fig/groupbyreducestage.pdf}
	    \bicaption[fig:groupbyreducestage]{单shuffle依赖工作的reduce阶段完成时间比较}{单shuffle依赖工作的reduce阶段完成时间比较}{Fig}{Map Stage Completion Time of Single Shuffle Test}
    \end{minipage}
\end{figure}

\begin{figure}[!htp]
    \centering
    \begin{minipage}[t]{0.47\textwidth}
	    \includegraphics[width=\textwidth]{../../PPoPP-2018/fig/groupbymaptask.pdf}
	    \bicaption[fig:groupbymaptask]{单shuffle依赖工作的map阶段中位任务比较}{单shuffle依赖工作的map阶段中位任务比较}{Fig}{Median Map Task Completion Time of Single Shuffle Test}
    \end{minipage}
    \begin{minipage}[t]{0.47\textwidth}
	    \includegraphics[width=\textwidth]{../../PPoPP-2018/fig/groupbyreducetask.pdf}
	    \bicaption[fig:groupbyreducetask]{单shuffle依赖工作的reduce阶段中位任务比较}{单shuffle依赖工作的reduce阶段中位任务比较}{Fig}{Median Reduce Task Completion Time of Single Shuffle Test}
    \end{minipage}
\end{figure}

具体到单个计算任务的角度，我们也记录了每个计算阶段中计算任务完成时间处于该阶段所有任务完成时间中位数的那个任务执行过程中具体的时间开销。
如图\ref{fig:groupbymaptask}和图\ref{fig:groupbyreducetask}所示，从任务执行过程中在各个部分的开销，能够进一步验证SCache优化过程的有效性。

在图\ref{fig:groupbymaptask}中的map阶段计算任务的执行过程比较中，可以看到通过SCache的将shuffle的磁盘写操作从map计算任务中解耦合之后，通过内存拷贝的方式可以优化大约40\%的shuffle数据写操作的开销。
之所以SCache的内存拷贝没有完全消除map计算任务中的shuffle写开销是因为在内存拷贝时，首先需要从Spark执行器的Java虚拟机中将shuffle数据移出。
而shuffle数据在Java虚拟机内存内部则是以Java类对象保存的，因此在将其移出内存空间时需要使用序列化的方法将类对象转换成字节码数组。
此处序列化的过程仍然会占用CPU的计算资源和时间\cite{makingsense}，并且是不可避免的，因此在图\ref{fig:groubymaptask}中仍然能观测到shuffle写过程的时间开销。
所以通过对于任务的细粒度分析，也应证了图\ref{fig:groupbymapstage}中，在map阶段SCache解耦shuffle写的过程并没有带来如reduce阶段那么多的收益。

结合图\ref{fig:groupbyreducetask}，可以观察到在Spark中，相较于map阶段shuffle写的时间开销，reduce阶段计算任务中shuffle读的开销占到整个任务执行时间的比例更大。
根据我们的实验检测发先该工作的reduce任务中，shuffle读取过程占到了reduce阶段计算任务的约50\%。
而这其中的大部分延迟是由网络传输带来的。
SCache通过在map计算阶段的早期对shuffle数据进行了预取，因此当reduce计算被Spark调度并且开始执行之前，通常情况下只有map计算阶段最后一轮的最后完成的几个任务产生的shuffle数据。
而这部分传输时间由于reduce任务调度的开销以及任务代码序列化等开销，也能被很好的隐藏起来。
一次在第一轮的reduce任务启动之后，SCache根据任务的预调度信息中的reduce任务ID等信息，已经将数据缓存在了内存当中。
因此可以看到在图\ref{groupbyreducetask}中，SCache可以通过shuffle数据预取将reduce计算任务开始之前的shuffle读等待时间几乎完全的隐藏起来。
也就说在SCache结合上下文的任务预调度与shuffle数据预取机制下，网络传输时间被很好的重叠在了map计算阶段和reduce计算阶段启动时期。

通过结合map阶段对shuffle数据写的优化以及reduce阶段对shuffle数据读的优化，SCache可以减少Spark的shuffle整体过程大约89\%的shuffle时间开销。

除此之外，在借助启发式算法的reduce任务预调度之后，SCache相较于Spark默认的FIFO算法，在负载均衡上有更好的表现。
在Spark默认的FIFO调度算法下，任务调度器会维护一个调度队列来保存当前仍未被执行的计算任务。
当调度器检测到有计算节点存在计算资源时，就会按照任务ID有小到大一次将任务分配给计算节点。
而默认情况下，一个CPU核心对应了一个slot执行槽，那么这种调度方式很可能会在初始阶段将几个计算量比较大的任务分配到同一个物理节点上，造成该节点的负载过大。
之所以会出现这种情况，是因为Spark默认调度算法并没有把每个任务需要的输入数据作为调度的一个参数进行考虑。
而在SCache的启发式算法中，因为调度时通过任务需要的输入体积来估计任务负载，从而将计算量较大的任务均匀分配到了集群的各个节点上，因此相较于Spark默认调度算法能获得更好的负载均衡。
这也是预调度在负载均衡上附带来的一部分优化。

\section{Terasort测试}

Terasort最初作为一个针对MapReduce集群性能测试的测试程序，目前被广泛地用来评测分布式并行计算框架以及其所在集群的性能。
该测试程序主要分为三个部分：数据生成，排序以及验证。
其中的排序部分被广泛的认为是一个需要大量数据进行shuffle的部分。
本文采用了Terasort在Spark上的一个实现\cite{terasort}来测试SCache对于Terasort在排序部分的优化效果。

在数据生成部分，Spark Terasort会根据指定的数据集大小，随机生成相应的测试数据，并存放在分布式存储系统，比如HDFS中。
在数据排序部分，程序首先采用了自定义的哈希分区函数--TeraSortPartitioner来对数据进行分区。
具体来讲，如代码片段\ref{code:tera}所示，该哈希分区函数结合了用户制定的分区数目（即$numPartitions$），通过对所有随机读入的数据的前缀进行取模计算，从而将该数据划分到对应的reduce计算任务中。
在此过程中，Spark会执行一次shuffle，将数据分别传输到各个reduce任务所对应的分区。
在Terasort的第二阶段，上一部执行的RDD会在此处通过调用$sortByKey()$的方法来在上一步已经粗略分区的基础上进行排序。
在此过程中，Spark首先采用了范围分区函数对现有的RDD进行重新分区，之后就会通过第二次shuffle过程，在reduce阶段对每个分区进行最后的排序。
范围分区函数在这里保证了reduce阶段每个分区都有明确的上下界，从而保证了分区之间的顺序。
而由于在第一阶段使用了根据前缀大小的粗略哈希分区，再加上数据生成部分的随机性，使得这一部分真正需要shuffle的数据量非常小，即shuffle的数据具有很强的本地倾斜性。
根据后续实验，我们发现第二次shuffle的过程中，对于依赖其数据的reduce任务，有93\%的数据是来自于本地某一个map任务的输出。
因此相较于第一个shuffle，在实验中我们将第二个shuffle作为测试SCache预调度机制在极端数据本地倾斜的情况下的调度结果。

\begin{lstlisting}[language={Java}, caption={Terasort哈希分区函数代码(Scala)}, label={code:tera}]
    val rangePerPart : Long = (max - min) / numPartitions

    def getPartition(key: Any): Int = {
        val b = key.asInstanceOf[Array[Byte]]
        val prefix = Longs.fromBytes(0, b(0), b(1), b(2), b(3), b(4), b(5), b(6))
        (prefix / rangePerPart).toInt
    }
\end{lstlisting}










