\subsection{Limitation and Future Work}
SCache aims to breach the shuffle cut off between DAG computing stages. And the evaluation results show a promising improvement. But we realize some limitations of SCache. 

\textbf{Fault tolerence of SCache}: When a failure happened on the SCache master, the whole system will stop working. To prevent the machine failure from leading to inconsistency(inconsisten) SCache, the master node will log the meta data of shuffle register and scheduling on the disk. Master can reads logs during recovery. Since we remove the shuffle transfer from the critical path of DAG computing, the disk log will not introduce extra overhead to the DAG frameworks. Note that the master can be implemented with Apache ZooKeeper\cite{zookeeper} to provide constantly service to DAG framework. If a failure happens on a worker, the optimization of tasks on that node will fail. It also violates the constraints of all-or-nothing, which means the gain of shuffle data cache maybe negligible. A promising way to solve the failure on worker is to reschedule reduce tasks and retransmit the data. Another solution is to select some backup nodes to store repcliations of shuffle data during scheduling to amortize the worker failure influences. We believe combing the high speed of network and memory is a better choice for fault tolerance. Since the mean time to failure(MTTF) for a server is counted in the scale of year\cite{tachyon}. As for now, fault tolerance is not a crucial goal of SCache,  we leave it to the future work.  

\textbf{Scheduling with different frameworks}: A cluster for data parallel computing always contains more than one frameworks. Setting priorities among jobs submitted from different framework is challenging and complex. However, combining the resource management facilities in data center such as Mesos\cite{mesos} may be a good direction.（integrating the resource management facilities in data center such as ... a good option?）